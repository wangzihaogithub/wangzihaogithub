---
layout: post
title:  "业务沉淀-技术难度(中)-业务复杂(高)-数据迁移(新老系统过渡切换)"
tags: 业务沉淀
---

### 开发了新系统, 老系统要平滑的过渡掉 (要处理的数据如下)

    1.期初业务数据
    2.期末业务数据
    3.过渡期实时产生的业务数据
    4.文件资源的迁移
    
    
### 难点

- 1.两边系统的领域对象的差异(例: 领域对象是候选人), 它们在逻辑上有的对应, 有的不对应, 而且表关系结构有差异. 但宏观上看是它们是相似的.

- 2.上线前要保证两边系统数据一致, 并且今后的几个月, 对老系统订单与元数据,基础数据的操作, 都要在3秒内及时更新到新系统中. 

- 3.老系统用户上传的文件也要同步到新系统中(比如简历文件)

- 4.两边的财务数据要严格一致,并且新系统能够根据老系统的数据出财务报表(年度,季度等)

- 5.业务会时不时的提出需求, 要清洗线上某领域对象的全部数据.(比如批量刷候选人拥有者)

### 如何解决?

刚开始就想的是两边数据同步一下就行, 写个定时任务跑跑, 简单搞一下. 

但写了一天发现越写越复杂, 而且还实现不了. 

因为领域对象的差异需要将数据读到内存里加业务逻辑, 读到内存里就要频繁产生IO操作, 

这样下去业务计算与大量的IO切换在单机上(8小时内运行完)基本不能实现,需要调优.

于是我想到用大数据框架, 但是还要搭建, 而且我对大数据不是专业的, 出了问题太花时间, 数据量也并不是那么大, 老系统的业务数据大概180G的样子吧


**索性简单写个数据处理, 参考flink的核心接口Iterable与Task**

要求它能够.

- 这次上线前能在8小时内将一切处理完成.

- 支持多机器同时跑.

- 执行完成后或异常停止时,可以让我知道, 能通知到我解决异常,完后它还能接着继续上次的跑

- 我不想写sql与建表,只想写业务判断和对象转换 (为了实现两边领域对象差异逻辑的代码).

- 支持流计算RDS (实现实时同步订单与基础数据)

- 支持批处理 (实现业务提出刷数据的需求)

- 支持数据顺序消费, 支持最终一致性 (实现两边数据严格一致)

- 两边系统的领域对象关系要留下,用于任意系统的数据在更新后能改变对方系统的数据. 并且能追溯数据的变更原因.

- 对外暴露http-api服务

### 细节

在初次模拟数据演练的时候, 发现项目一直没打印启动成功的提示信息. 

后来发现卡在了一个count的sql上, 

因为项目在启动时, 我会检查元数据的初始化去count一下, 因为数据量太大了960W条, count就直接卡死了. 

后来改成explan了, 大概知道数据量够,就不初始化元数据了(元数据就是那些两边系统枚举对应关系与两边系统ID对应关系). 

### 获得

后续关于数据的需求, 我都在推这个项目.

因为这个项目足够简单, 写一个功能后, 右键直接启动或单元测试, 立马见效. 而且在wiki写有文档.

这个框架可以长期使用 (涉及到数据的抽取,清洗,转换, 在没开C端业务的情况下)

### 总结

- 上线前(准备环境(准备多个服务器部署程序跑数据,上线脚本),预估时间(调优,减少上线时间),监控,故障演练,回退策略) 

- 上线时(时刻关注进度监控, 与异常, 与数据量)

- 上线后(校验数据,查看存储大小)

- 进入过渡期(两系统同时运行, 这时业务数据主要从一边出)

- 过渡期结束(仅剩新系统, 要对老系统数据校验(比如人才拥有者比对)

- 新系统加工数据,产生业务价值 (数据清洗输出)


![谷露同步逻辑](../../../images/postimg/谷露同步逻辑.png)
